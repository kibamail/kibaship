# ==============================================================================
# KIBASHIP INGRESS IMPLEMENTATION TASK LIST
# ==============================================================================
# This file tracks all tasks required to implement the Gateway API-based
# ingress architecture documented in ingress.yaml
#
# Status values: [ ] TODO, [~] IN PROGRESS, [x] DONE, [!] NEEDS CHANGE
# ==============================================================================

# ==============================================================================
# PHASE 1: BOOTSTRAP & INFRASTRUCTURE SETUP
# Timing: One-time cluster initialization / operator installation
# ==============================================================================
bootstrap:
  description: "Infrastructure setup that happens once during cluster/operator bootstrap"

  gateway_api_crds:
    - status: "[x]"
      task: "Install Gateway API CRDs (v1.2.0+)"
      timing: "On cluster bootstrap, before operator starts"
      location: "EXTERNAL - Handled by cluster installation, not operator"
      details: |
        Gateway API CRDs are installed via cluster setup scripts or Helm charts.
        The operator assumes these CRDs are already present.
        - GatewayClass
        - Gateway
        - HTTPRoute
        - TLSRoute (experimental/alpha)
        - ReferenceGrant
      acceptance_criteria:
        - kubectl get crd gatewayclasses.gateway.networking.k8s.io
        - kubectl get crd gateways.gateway.networking.k8s.io
        - kubectl get crd httproutes.gateway.networking.k8s.io
        - kubectl get crd tlsroutes.gateway.networking.k8s.io
        - kubectl get crd referencegrants.gateway.networking.k8s.io
      notes: "MARKED AS DONE - Handled outside operator scope"

  cilium_installation:
    - status: "[x]"
      task: "Install/Configure Cilium with Gateway API support"
      timing: "On cluster bootstrap, before operator starts"
      location: "EXTERNAL - Handled by cluster installation, not operator"
      details: |
        Cilium CNI with Gateway API support is installed via cluster setup.
        The operator assumes Cilium is already running with:
        - Gateway API enabled (gatewayAPI.enabled=true)
        - L7 proxy enabled
        - NodePort enabled
      acceptance_criteria:
        - cilium status shows healthy
        - Gateway API support is enabled
        - Cilium Gateway controller is running
      notes: "MARKED AS DONE - Handled outside operator scope"

  gateway_api_system_namespace:
    - status: "[x]"
      task: "Create gateway-api-system namespace"
      timing: "On operator startup"
      location: "internal/bootstrap/provision.go:28,75"
      current_implementation: |
        ✅ COMPLETED
        const gatewayAPISystemNS = "gateway-api-system"

        Namespace created via ensureNamespace() call
      changes_made: |
        1. Updated constant at line 28 from ingressGatewayNS to gatewayAPISystemNS
        2. Changed value from "ingress-gateway" to "gateway-api-system"
        3. Updated all references throughout the file
        4. ensureNamespace() now creates gateway-api-system namespace
      acceptance_criteria:
        - kubectl get namespace gateway-api-system
        - Namespace created on operator startup
      notes: "COMPLETED - Namespace renamed to gateway-api-system"

  certificates_namespace:
    - status: "[x]"
      task: "Create certificates namespace"
      timing: "On operator startup"
      location: "internal/bootstrap/provision.go:75-79"
      current_implementation: |
        ✅ ALREADY IMPLEMENTED
        const certificatesNS = "certificates"

        Creates namespace via ensureNamespace() at line 75-79
      acceptance_criteria:
        - kubectl get namespace certificates
      notes: "ALREADY DONE - No changes needed"

  gateway_resource:
    - status: "[x]"
      task: "Create shared Gateway resource in gateway-api-system namespace"
      timing: "On operator startup, after Cilium is ready"
      location: "internal/bootstrap/provision.go:197-292"
      current_implementation: |
        ✅ COMPLETED
        Function: ensureGateway() at lines 197-292

        Creates Gateway with 5 listeners:
        - HTTP (port 80)
        - HTTPS (port 443) with TLS termination
        - MySQL TLS (port 3306) with passthrough
        - Valkey TLS (port 6379) with passthrough
        - PostgreSQL TLS (port 5432) with passthrough
      changes_made: |
        ADDED NEW FUNCTION: ensureGateway()

        Create function in internal/bootstrap/provision.go:

        func ensureGateway(ctx context.Context, c client.Client) error {
          obj := &unstructured.Unstructured{}
          obj.SetGroupVersionKind(schema.GroupVersionKind{
            Group:   "gateway.networking.k8s.io",
            Version: "v1",
            Kind:    "Gateway",
          })
          obj.SetNamespace(gatewayAPISystemNS)
          obj.SetName("kibaship-gateway")

          if err := c.Get(ctx, client.ObjectKey{
            Namespace: gatewayAPISystemNS,
            Name:      "kibaship-gateway",
          }, obj); err != nil {
            if !errors.IsNotFound(err) {
              return err
            }

            // Create Gateway with multi-protocol listeners
            obj.Object["spec"] = map[string]any{
              "gatewayClassName": "cilium",
              "listeners": []any{
                // HTTP listener
                map[string]any{
                  "name":     "http",
                  "protocol": "HTTP",
                  "port":     int64(80),
                  "allowedRoutes": map[string]any{
                    "namespaces": map[string]any{"from": "All"},
                  },
                },
                // HTTPS listener
                map[string]any{
                  "name":     "https",
                  "protocol": "HTTPS",
                  "port":     int64(443),
                  "tls": map[string]any{
                    "mode": "Terminate",
                    "certificateRefs": []any{
                      map[string]any{
                        "name":      "tenant-wildcard-certificate",
                        "namespace": certificatesNS,
                        "kind":      "Secret",
                      },
                    },
                  },
                  "allowedRoutes": map[string]any{
                    "namespaces": map[string]any{"from": "All"},
                  },
                },
                // MySQL TLS listener
                map[string]any{
                  "name":     "mysql-tls",
                  "protocol": "TLS",
                  "port":     int64(3306),
                  "tls": map[string]any{"mode": "Passthrough"},
                  "allowedRoutes": map[string]any{
                    "namespaces": map[string]any{"from": "All"},
                    "kinds": []any{
                      map[string]any{"kind": "TLSRoute"},
                    },
                  },
                },
                // Valkey TLS listener
                map[string]any{
                  "name":     "valkey-tls",
                  "protocol": "TLS",
                  "port":     int64(6379),
                  "tls": map[string]any{"mode": "Passthrough"},
                  "allowedRoutes": map[string]any{
                    "namespaces": map[string]any{"from": "All"},
                    "kinds": []any{
                      map[string]any{"kind": "TLSRoute"},
                    },
                  },
                },
                // PostgreSQL TLS listener
                map[string]any{
                  "name":     "postgres-tls",
                  "protocol": "TLS",
                  "port":     int64(5432),
                  "tls": map[string]any{"mode": "Passthrough"},
                  "allowedRoutes": map[string]any{
                    "namespaces": map[string]any{"from": "All"},
                    "kinds": []any{
                      map[string]any{"kind": "TLSRoute"},
                    },
                  },
                },
              },
            }

            return c.Create(ctx, obj)
          }
          return nil
        }

        CALL IT from ProvisionIngressAndCertificates() after namespace creation:
        - After line 79, add:
          if err := ensureGateway(ctx, c); err != nil {
            return fmt.Errorf("ensure Gateway: %w", err)
          }
      acceptance_criteria:
        - kubectl get gateway -n gateway-api-system kibaship-gateway
        - Gateway status shows Programmed=True
        - LoadBalancer service created with ports: 80, 443, 3306, 6379, 5432
      notes: "TODO - New function needed"

  wildcard_certificates:
    - status: "[x]"
      task: "Create wildcard certificate for web apps"
      timing: "On operator startup, after cert-manager is ready"
      location: "internal/bootstrap/provision.go:154-168"
      current_implementation: |
        ✅ COMPLETED
        Function creates wildcard certificate for web apps:

        ensureWildcardCertificate() at line 154-168
           Creates: tenant-wildcard-certificate (*.apps.{baseDomain})

        Called from ProvisionIngressAndCertificates()
      changes_made: |
        COMPLETED:

        1. Updated ensureWildcardCertificate() to use *.apps.{baseDomain}
           Changed dnsNames from *.{baseDomain} to *.apps.{baseDomain}

        2. REMOVED database-wildcard-certificate
           Each database now gets its own individual certificate in its project namespace
           Certificates created by ApplicationDomainReconciler, not bootstrap
      acceptance_criteria:
        - kubectl get certificate -n certificates tenant-wildcard-certificate
        - kubectl get secret -n certificates tenant-wildcard-certificate
        - tenant-wildcard-certificate covers *.apps.{domain}
        - Certificate shows Ready=True
      notes: "COMPLETED - Database certificates handled per-instance by reconciler"

  gateway_reference_grant:
    - status: "[x]"
      task: "Create ReferenceGrant for Gateway to access certificates"
      timing: "On operator startup, after certificates namespace exists"
      location: "internal/bootstrap/provision.go:294-331"
      current_implementation: |
        ✅ COMPLETED
        Function: ensureGatewayReferenceGrant() at lines 294-331

        Creates ReferenceGrant dynamically:
          from:
            - namespace: gateway-api-system
              kind: Gateway
          to:
            - kind: Secret (all secrets allowed)
      changes_made: |
        IMPLEMENTED OPTION 2: Dynamic creation in bootstrap
        ---
        apiVersion: gateway.networking.k8s.io/v1beta1
        kind: ReferenceGrant
        metadata:
          name: gateway-to-certificates
          namespace: certificates
        spec:
          from:
            - group: gateway.networking.k8s.io
              kind: Gateway
              namespace: gateway-api-system  # CHANGED
          to:
            - group: ""
              kind: Secret  # CHANGED - allow all secrets

        OPTION 2: Create dynamically in bootstrap (RECOMMENDED)
        Add function ensureGatewayReferenceGrant() in internal/bootstrap/provision.go

        func ensureGatewayReferenceGrant(ctx context.Context, c client.Client) error {
          obj := &unstructured.Unstructured{}
          obj.SetGroupVersionKind(schema.GroupVersionKind{
            Group: "gateway.networking.k8s.io", Version: "v1beta1", Kind: "ReferenceGrant",
          })
          obj.SetNamespace(certificatesNS)
          obj.SetName("gateway-to-certificates")

          if err := c.Get(ctx, client.ObjectKey{Namespace: certificatesNS, Name: "gateway-to-certificates"}, obj); err != nil {
            if !errors.IsNotFound(err) {
              return err
            }
            obj.Object["spec"] = map[string]any{
              "from": []any{
                map[string]any{
                  "group":     "gateway.networking.k8s.io",
                  "kind":      "Gateway",
                  "namespace": gatewayAPISystemNS,
                },
              },
              "to": []any{
                map[string]any{"group": "", "kind": "Secret"},
              },
            }
            return c.Create(ctx, obj)
          }
          return nil
        }

        Call it after Gateway creation in ProvisionIngressAndCertificates()
      acceptance_criteria:
        - kubectl get referencegrant -n certificates gateway-to-certificates
        - ReferenceGrant allows Gateway in gateway-api-system to access Secrets in certificates
      notes: "NEEDS CHANGE - Wrong namespace reference, create dynamically"

  gateway_tls_configuration:
    - status: "[x]"
      task: "Configure Gateway HTTPS listener to use wildcard certificate"
      timing: "On operator startup, as part of Gateway creation"
      location: "internal/bootstrap/provision.go:197-292 (part of ensureGateway)"
      current_implementation: |
        ✅ COMPLETED
        Included in ensureGateway() function

        The HTTPS listener includes:
        "tls": map[string]any{
          "mode": "Terminate",
          "certificateRefs": []any{
            map[string]any{
              "name":      "tenant-wildcard-certificate",
              "namespace": certificatesNS,
              "kind":      "Secret",
            },
          },
        }
      changes_made: |
        TLS configuration implemented as part of ensureGateway() function
      acceptance_criteria:
        - Gateway HTTPS listener references tenant-wildcard-certificate
        - TLS termination works for *.apps.{domain}
      notes: "COMPLETED - Part of Gateway creation"

  remove_old_httproutes:
    - status: "[x]"
      task: "Remove old HTTPRoute creation logic from bootstrap"
      timing: "During refactoring"
      location: "internal/bootstrap/provision.go"
      current_implementation: |
        ✅ COMPLETED
        Old HTTPRoute functions have been removed

        New architecture uses per-project HTTPRoutes created by
        ApplicationDomainReconciler, not global wildcard routes.
      changes_made: |
        REMOVED these functions:

        1. DELETED functions:
           - ensureHTTPRedirectRoute()
           - ensureHTTPSRoute()
           - ensureDeploymentNotFoundRoute()
           - ensureDeploymentNotFoundWorkload()

        2. REMOVED calls in ProvisionIngressAndCertificates():
           - Removed ensureHTTPRedirectRoute() call
           - Removed ensureHTTPSRoute() call
           - Removed ensureDeploymentNotFoundRoute() call
           - Removed ensureDeploymentNotFoundWorkload() call
      acceptance_criteria:
        - Old HTTPRoute functions removed
        - Old HTTPRoute calls removed from bootstrap
        - No HTTPRoutes created at bootstrap
        - Code compiles successfully
      notes: "COMPLETED - Old ingress-gateway approach removed"

  update_constants:
    - status: "[x]"
      task: "Update constants for new architecture"
      timing: "During refactoring"
      location: "internal/bootstrap/provision.go:26-32"
      current_implementation: |
        ✅ COMPLETED

        const (
          certificatesNS              = "certificates"
          gatewayAPISystemNS          = "gateway-api-system"
          issuerName                  = "certmanager-acme-issuer"
          wildcardCertName            = "tenant-wildcard-certificate"
          databaseWildcardCertName    = "database-wildcard-certificate"
          gatewayName                 = "kibaship-gateway"
        )
      changes_made: |
        UPDATED constants:

        1. Renamed ingressGatewayNS to gatewayAPISystemNS
        2. Changed value from "ingress-gateway" to "gateway-api-system"
        3. Added databaseWildcardCertName = "database-wildcard-certificate"
        4. Renamed gatewayName from "ingress-gateway" to "kibaship-gateway"
        5. Removed deploymentNFName (no longer needed)
      acceptance_criteria:
        - Constants updated
        - All references updated throughout the file
        - Code compiles successfully
      notes: "COMPLETED - Constants aligned with new architecture"

  dynamic_provisioning_only:
    - status: "[x]"
      task: "Use ONLY dynamic provisioning for all ingress resources"
      timing: "Bootstrap (operator startup)"
      location: "internal/bootstrap/provision.go"
      current_implementation: |
        ✅ COMPLETED: All ingress and certificate resources are created dynamically

        The operator creates ALL resources programmatically in bootstrap code:
          - Namespaces (certificates, gateway-api-system)
          - ClusterIssuer (certmanager-acme-issuer)
          - Wildcard Certificate for web apps (*.apps.{domain})
          - Gateway resource with 5 listeners
          - ReferenceGrant for cross-namespace certificate access

        NO STATIC KUSTOMIZATION FILES USED.

        Static config/certificates directory has been REMOVED as it was redundant.
        The old static files were:
          - namespace.yaml (redundant - created by ensureNamespace)
          - referencegrant.yaml (outdated - used old namespace name, created by ensureGatewayReferenceGrant)
          - kustomization.yaml (references the above files)
      acceptance_criteria:
        - config/certificates directory does NOT exist
        - All resources created dynamically by operator bootstrap
        - No static YAML files for ingress/gateway resources
        - Operator handles all resource lifecycle
      notes: "COMPLETED - Dynamic provisioning only, no static kustomization files"

# ==============================================================================
# BOOTSTRAP PHASE SUMMARY
# ==============================================================================
bootstrap_summary:
  total_tasks: 10
  status_breakdown:
    completed: 10  # ALL BOOTSTRAP TASKS COMPLETED
    needs_change: 0
    todo: 0
    in_progress: 0

  what_was_implemented:
    - "✅ Namespace creation logic (certificates, gateway-api-system)"
    - "✅ ClusterIssuer creation (certmanager-acme-issuer)"
    - "✅ Wildcard certificate for web apps (*.apps.{domain})"
    - "✅ Gateway resource with 5 multi-protocol listeners"
    - "✅ ReferenceGrant for Gateway to access certificates"
    - "✅ ConfigMap loading for domain and ACME email"
    - "✅ Bootstrap function called on operator startup"
    - "✅ Old HTTPRoute logic removed"
    - "✅ Constants updated for new architecture"
    - "✅ Comprehensive unit tests (8 tests, all passing)"

  changes_made:
    - "✅ Namespace name: ingress-gateway → gateway-api-system"
    - "✅ Gateway name: ingress-gateway → kibaship-gateway"
    - "✅ REMOVED database wildcard certificate - databases get individual certs"
    - "✅ Database domains use separate subdomains: *.mysql, *.postgres, *.valkey"
    - "✅ Removed old HTTPRoute creation (global wildcard routes)"
    - "✅ Removed deployment-not-found workload"
    - "✅ Created dynamic ReferenceGrant in bootstrap"
    - "✅ Added Gateway resource creation with 5 listeners (HTTP, HTTPS, MySQL, Valkey, PostgreSQL)"
    - "✅ Updated wildcard certificate to use *.apps.{domain}"

  files_modified:
    - "internal/bootstrap/provision.go (major refactoring completed)"
    - "internal/bootstrap/provision_test.go (comprehensive test suite added)"
    - "config/certificates/ (DELETED - redundant static files removed)"

  test_results:
    - "✅ TestEnsureGateway: PASS (2/2 test cases)"
    - "✅ TestEnsureGatewayReferenceGrant: PASS (2/2 test cases)"
    - "✅ TestEnsureWildcardCertificate: PASS (2/2 test cases)"
    - "✅ TestEnsureClusterIssuer: PASS (2/2 test cases)"
    - "✅ All unit tests passing (8/8)"
    - "Note: TestEnsureDatabaseWildcardCertificate removed - databases get individual certs"

# ==============================================================================
# PHASE 2: OPERATOR CODE CHANGES
# Timing: Development tasks to implement reconciler logic
# ==============================================================================
operator_code:
  description: "Code changes to operator controllers and utilities"

  deployment_reconciler_types:
    - status: "[x]"
      task: "Add new deployment phases to Deployment types"
      timing: "Development"
      location: "api/v1alpha1/deployment_types.go:46"
      details: |
        ✅ COMPLETED

        Add new phase constant:
        - DeploymentPhaseDeploying DeploymentPhase = "Deploying"

        This phase indicates Kubernetes resources are being created after build
      current_implementation: |
        DeploymentPhaseDeploying constant already exists at line 46:

        const (
          DeploymentPhaseInitializing DeploymentPhase = "Initializing"
          DeploymentPhasePreparing DeploymentPhase = "Preparing"
          DeploymentPhaseBuilding DeploymentPhase = "Building"
          DeploymentPhaseDeploying DeploymentPhase = "Deploying"  // ✅ Already defined
          DeploymentPhaseRunning DeploymentPhase = "Running"
          DeploymentPhaseSucceeded DeploymentPhase = "Succeeded"
          DeploymentPhaseFailed DeploymentPhase = "Failed"
          DeploymentPhaseWaiting DeploymentPhase = "Waiting"
        )
      acceptance_criteria:
        - New phase constant defined ✅
        - Kubebuilder validation updated ✅
        - make generate and make manifests run successfully ✅
      notes: "COMPLETED - Phase constant was already defined"

  random_slug_generator:
    - status: "[x]"
      task: "Create random slug generator utility"
      timing: "Development"
      location: "pkg/utils/slug.go:85-115"
      details: |
        ✅ COMPLETED

        Function to generate human-readable random slugs:
        - Format: <adjective>-<noun>-<random-chars>
        - Example: copper-forest-7x9k, silver-lake-5k3x
        - Use for subdomain generation
      current_implementation: |
        IMPLEMENTED GenerateHumanReadableSlug() function at line 85-115:

        func GenerateHumanReadableSlug() (string, error) {
          // Picks random adjective from 100+ adjectives
          // Picks random noun from 90+ nouns
          // Generates 4-character random suffix
          // Returns: <adjective>-<noun>-<random-suffix>
          // Example: "copper-forest-7x9k"
        }

        Features:
        - 100+ adjectives (autumn, copper, silver, golden, etc.)
        - 90+ nouns (waterfall, river, forest, ocean, etc.)
        - 4-character random suffix for uniqueness
        - DNS-compatible output
        - Cryptographically secure random selection

        Also kept existing GenerateRandomSlug() for backward compatibility
      test_coverage: |
        Added comprehensive unit tests in test/utils/slug_test.go:

        1. Format validation (matches <adjective>-<noun>-<random>)
        2. DNS compatibility validation
        3. Uniqueness testing (100 slugs, all unique)
        4. Word structure validation (3 parts, correct patterns)
        5. Random suffix uniqueness (90%+ unique in 100 samples)
        6. Human-readability validation

        All tests passing: 11/11 ✅
      acceptance_criteria:
        - Function generates unique, DNS-compatible slugs ✅
        - Slugs match pattern: [a-z0-9]([a-z0-9-]*[a-z0-9])? ✅
        - Unit tests for slug generation ✅
      notes: "COMPLETED - Human-readable slug generator with extensive word lists (400+ adjectives, 360+ nouns)"

  deployment_reconciler_k8s_deployment:
    - status: "[x]"
      task: "Implement createKubernetesDeployment in DeploymentReconciler"
      timing: "Development"
      location: "internal/controller/deployment_controller.go:337-517"
      details: |
        ✅ COMPLETED

        Implemented Kubernetes Deployment creation in DeploymentReconciler:
        - Image name derived from deployment labels (namespace/app-uuid:deployment-uuid)
        - No need to extract from PipelineRun results - derived directly
        - Deployment created with:
          * Name: deployment-<slug>-kibaship-com
          * Container image: registry.registry.svc.cluster.local/{namespace}/{app-uuid}:{deployment-uuid}
          * Container port: 3000 (default)
          * Resource limits from Project spec (ResourceProfile: minimal/standard/performance)
        - Set OwnerReference to Deployment CR for cascading deletion

        Reference: See ingress.yaml section 6.2 for pseudocode
      current_implementation: |
        Added helper function getImageName() at lines 337-344:
          - Derives image name from deployment labels
          - Format: registry.registry.svc.cluster.local/{namespace}/{app-uuid}:{deployment-uuid}

        Added createKubernetesDeployment() function at lines 346-517:
          - Checks if Kubernetes Deployment already exists
          - Fetches parent Project for resource profile
          - Determines resource limits based on profile:
            * minimal: 250m CPU, 256Mi memory
            * standard: 500m CPU, 512Mi memory
            * performance: 1000m CPU, 1Gi memory
          - Creates Deployment with proper labels and owner references
          - Defaults to "standard" profile if not specified

        Integrated into reconcile loop at lines 160-174:
          - Triggers when phase is DeploymentPhaseDeploying
          - Creates K8s Deployment
          - Transitions to DeploymentPhaseSucceeded after creation

        Added RBAC permissions at lines 73, 78-80:
          - apps/deployments (get, list, watch, create, update, patch, delete)
          - core/services (get, list, watch, create, update, patch, delete)
          - platform.operator.kibaship.com/projects (get, list, watch)

        Updated SetupWithManager at line 1327:
          - Added .Owns(&appsv1.Deployment{}) for automatic reconciliation
      acceptance_criteria:
        - ✅ Function creates valid Kubernetes Deployment
        - ✅ OwnerReference set correctly
        - ✅ Image derived from deployment labels (no PipelineRun result extraction needed)
        - ✅ Resource limits set from Project resource profile
        - ✅ RBAC permissions added
        - ✅ Build successful
        - ✅ All tests passing (controller tests: 27 passed, 1 skipped)
      notes: "COMPLETED - Kubernetes Deployment creation implemented, all tests passing"

  deployment_reconciler_k8s_service:
    - status: "[x]"
      task: "Implement createKubernetesService in DeploymentReconciler"
      timing: "Development"
      location: "internal/controller/deployment_controller.go:673-743"
      details: |
        ✅ COMPLETED

        Implemented createKubernetesService() function:
        - Name: service-{appUUID} (line 679)
        - Type: ClusterIP (line 716)
        - Selector matches Deployment pods (lines 717-720)
        - Port: default 3000 with TODO for ApplicationDomain integration (line 699)
        - OwnerReference set to Deployment CR (line 733)
        - Called in reconcile loop during Deploying phase (line 247)

        Reference: See ingress.yaml section 6.2 for pseudocode
      current_implementation: |
        Function at lines 673-743:

        func (r *DeploymentReconciler) createKubernetesService(...) error {
          serviceName := fmt.Sprintf("service-%s", appUUID)

          // Check if Service already exists (idempotent)
          // Determine container port (default 3000, TODO: get from ApplicationDomain)

          service := &corev1.Service{
            ObjectMeta: metav1.ObjectMeta{
              Name:      serviceName,
              Namespace: deployment.Namespace,
              Labels:    {...},
            },
            Spec: corev1.ServiceSpec{
              Type: corev1.ServiceTypeClusterIP,
              Selector: map[string]string{
                "app.kubernetes.io/name":                 fmt.Sprintf("app-%s", appUUID),
                "platform.kibaship.com/application-uuid": app.Labels["platform.kibaship.com/uuid"],
              },
              Ports: []corev1.ServicePort{
                {Name: "http", Protocol: TCP, Port: containerPort, TargetPort: containerPort},
              },
            },
          }

          // Set owner reference
          controllerutil.SetControllerReference(deployment, service, r.Scheme)

          // Create service
          r.Create(ctx, service)
        }

        Called from Reconcile() at line 247:
        if deployment.Status.Phase == DeploymentPhaseDeploying {
          r.createKubernetesDeployment(...)
          r.createKubernetesService(...)  // ✅ Called here
          ...
        }
      acceptance_criteria:
        - ✅ Function creates valid Service
        - ✅ Service routes to correct pods via selector
        - ✅ Endpoints are populated by Kubernetes
        - ✅ OwnerReference enables cascading deletion
        - ✅ Service is idempotent (checks for existing service)
      notes: "COMPLETED - Service creation fully implemented and integrated into deployment flow"

  deployment_reconciler_domain_creation:
    - status: "[x]"
      task: "Implement ensureApplicationDomain in DeploymentReconciler"
      timing: "Development"
      location: "internal/controller/deployment_controller.go:745-849"
      details: |
        ✅ COMPLETED

        Implemented ensureApplicationDomain() function at lines 745-849:
        - Checks if default domain already exists for the application
        - Uses utils.GenerateHumanReadableSlug() for domain slug generation
        - Determines domain pattern based on Application type:
          * Web apps (GitRepository, DockerImage): <slug>.apps.<baseDomain>
          * MySQL databases: <slug>.mysql.<baseDomain> with port 3306
          * PostgreSQL databases: <slug>.postgres.<baseDomain> with port 5432
        - Creates ApplicationDomain CR with:
          * Type: ApplicationDomainTypeDefault
          * Default: true
          * TLSEnabled: true
          * Port based on application type (3000 for web, 3306 for MySQL, 5432 for PostgreSQL)
          * OwnerReference to Deployment CR for cascading deletion

        Integration into reconcile loop at line 255:
        - Called after createKubernetesDeployment() and createKubernetesService()
        - Only for GitRepository applications in Deploying phase
        - Part of the deployment resource creation flow

        RBAC permissions added at line 116:
        - platform.operator.kibaship.com/applicationdomains (get, list, watch, create, update, patch, delete)

        SetupWithManager updated at line 1915:
        - Added .Owns(&platformv1alpha1.ApplicationDomain{}) for automatic reconciliation

        Reference: See ingress.yaml section 6.2 for pseudocode
      current_implementation: |
        func (r *DeploymentReconciler) ensureApplicationDomain(ctx context.Context, deployment *platformv1alpha1.Deployment, app *platformv1alpha1.Application) error {
          // Check if default domain already exists
          var domainList platformv1alpha1.ApplicationDomainList
          err := r.List(ctx, &domainList, client.InNamespace(deployment.Namespace), client.MatchingLabels{
            "platform.kibaship.com/application-uuid": appUUID,
          })

          for _, domain := range domainList.Items {
            if domain.Spec.Default {
              return nil // Already exists
            }
          }

          // Get operator configuration for base domain
          opConfig, err := GetOperatorConfig()

          // Generate random slug for domain
          slug, err := utils.GenerateHumanReadableSlug()

          // Determine domain pattern based on Application type
          switch app.Spec.Type {
          case ApplicationTypeGitRepository, ApplicationTypeDockerImage:
            domain = fmt.Sprintf("%s.apps.%s", slug, opConfig.Domain)
          case ApplicationTypeMySQL, ApplicationTypeMySQLCluster:
            domain = fmt.Sprintf("%s.mysql.%s", slug, opConfig.Domain)
            port = 3306
          case ApplicationTypePostgres, ApplicationTypePostgresCluster:
            domain = fmt.Sprintf("%s.postgres.%s", slug, opConfig.Domain)
            port = 5432
          }

          // Create ApplicationDomain CR
          applicationDomain := &platformv1alpha1.ApplicationDomain{
            ObjectMeta: metav1.ObjectMeta{
              Name:      fmt.Sprintf("domain-%s", domainUUID),
              Namespace: deployment.Namespace,
              Labels:    {...},
            },
            Spec: platformv1alpha1.ApplicationDomainSpec{
              ApplicationRef: corev1.LocalObjectReference{Name: app.Name},
              Domain:     domain,
              Port:       port,
              Type:       platformv1alpha1.ApplicationDomainTypeDefault,
              Default:    true,
              TLSEnabled: true,
            },
          }

          controllerutil.SetControllerReference(deployment, applicationDomain, r.Scheme)
          return r.Create(ctx, applicationDomain)
        }
      acceptance_criteria:
        - ✅ Function creates ApplicationDomain CR
        - ✅ Domain follows correct pattern (<slug>.apps/mysql/postgres.<baseDomain>)
        - ✅ Labels set correctly (UUID, slug, project-uuid, application-uuid)
        - ✅ Only one default domain per application (checked before creation)
        - ✅ OwnerReference set for cascading deletion
        - ✅ RBAC permissions added
        - ✅ SetupWithManager updated
      notes: "COMPLETED - Default ApplicationDomain creation implemented for web and database applications"

  deployment_progress_controller_resource_creation:
    - status: "[x]"
      task: "Complete K8s resource creation in DeploymentProgressController"
      timing: "Development"
      location: "internal/controller/deployment_progress_controller.go:190-434"
      details: |
        ✅ COMPLETED

        ⚠️ TASK WAS REWRITTEN to match 3-controller architecture

        The deployment flow uses 3 controllers:
        1. DeploymentReconciler: Creates Deployment CR, PipelineRun, and initial resources
        2. PipelineRunStatusController: Updates Deployment conditions from PipelineRun status
        3. DeploymentProgressController: Manages phase transitions based on conditions

        This task focused on #3: Complete the stub implementations in DeploymentProgressController.

        Implementation completed:
        1. ✅ Implemented ensureKubernetesDeployment() at lines 190-361
           - Creates K8s Deployment with image from registry
           - Sets resource limits based on profile (minimal/standard/performance)
           - Configures image pull secrets and registry CA certificate
           - Sets OwnerReference to Deployment CR for cascading deletion
           - Idempotent (checks for existing deployment)

        2. ✅ Implemented ensureKubernetesService() at lines 364-434
           - Creates ClusterIP Service
           - Configures selectors to match Deployment pods
           - Sets OwnerReference to Deployment CR for cascading deletion
           - Idempotent (checks for existing service)

        3. ✅ Removed duplicate logic from DeploymentReconciler
           - Removed K8s resource creation from DeploymentReconciler.Reconcile() (lines 239-267 removed)
           - Added clear documentation explaining the separation of concerns
           - DeploymentReconciler now focuses ONLY on CR and PipelineRun creation

        4. ✅ Added necessary imports
           - k8s.io/apimachinery/pkg/api/resource (for resource limits)
           - k8s.io/apimachinery/pkg/util/intstr (for service ports)

        Phase flow implemented:
        Initializing -> Building (PipelineRun running) -> Deploying (K8s resources created) -> Succeeded (pods ready)

        Files modified:
        - internal/controller/deployment_progress_controller.go (implemented stubs)
        - internal/controller/deployment_controller.go (removed duplicate creation logic)

        Reference: See ingress.yaml section 6.2 for complete flow
      acceptance_criteria:
        - ✅ ensureKubernetesDeployment() creates valid K8s Deployment
        - ✅ ensureKubernetesService() creates valid Service
        - ✅ State machine transitions: Building -> Deploying -> Succeeded
        - ✅ Pods become ready and phase transitions to Succeeded (via computeTargetPhase logic)
        - ✅ No duplicate resource creation logic between controllers
        - ✅ Resources have correct OwnerReferences
        - ✅ Reconciler handles errors gracefully (returns errors for retry)
        - ✅ Code compiles successfully (go build passed)
        - ✅ make generate and make manifests run successfully
      notes: |
        COMPLETED - DeploymentProgressController now fully manages post-build K8s resource creation

        NOTE: ApplicationDomain creation was also removed from DeploymentReconciler as part of this refactoring.
        If ApplicationDomain creation is needed, it should be added either:
        1. Back to DeploymentReconciler (for early domain reservation)
        2. Or to DeploymentProgressController (for post-build domain creation)

        This can be addressed in a follow-up task if needed.

  deployment_reconciler_status_tracking:
    - status: "[ ]"
      task: "Track Kubernetes resource references in Deployment status"
      timing: "Development"
      location: "api/v1alpha1/deployment_types.go"
      details: |
        Add fields to DeploymentStatus to track created resources:
        - KubernetesDeploymentName string
        - ServiceName string
        - ApplicationDomainRef *corev1.LocalObjectReference

        Update DeploymentReconciler to populate these fields
      acceptance_criteria:
        - Status fields defined
        - Fields populated during reconciliation
        - Status reflects current resource state

  application_domain_reconciler_app_type_detection:
    - status: "[ ]"
      task: "Implement Application type detection in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add helper function to determine if Application is:
        - Web application (GitRepository, DockerImage)
        - Database application (MySQL, Valkey, PostgreSQL)

        This determines whether to create HTTPRoute or TLSRoute
      acceptance_criteria:
        - Function correctly identifies app types
        - Returns appropriate routing strategy

  application_domain_reconciler_httproute:
    - status: "[ ]"
      task: "Implement HTTPRoute creation in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add function to create HTTPRoute for web applications:
        - Name: httproute-<domain-slug>
        - ParentRefs: kibaship-gateway (https listener)
        - Hostname from ApplicationDomain.Spec.Domain
        - BackendRef to Service on ApplicationDomain.Spec.Port
        - Set OwnerReference to ApplicationDomain CR

        Also create HTTP->HTTPS redirect HTTPRoute:
        - Name: httproute-<domain-slug>-redirect
        - ParentRefs: kibaship-gateway (http listener)
        - RequestRedirect filter to HTTPS

        Reference: See ingress.yaml section 3.2 and 3.3
      acceptance_criteria:
        - HTTPRoute created with correct spec
        - Routes attached to Gateway
        - Traffic routes to correct Service
        - HTTPS works with wildcard certificate
        - HTTP redirects to HTTPS

  application_domain_reconciler_tlsroute:
    - status: "[ ]"
      task: "Implement TLSRoute creation in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add function to create TLSRoute for database applications:
        - Name: tlsroute-<domain-slug>
        - ParentRefs: kibaship-gateway (appropriate TLS listener)
        - Listener selection based on Application type:
          * MySQL -> mysql-tls listener
          * Valkey -> valkey-tls listener
          * PostgreSQL -> postgres-tls listener
        - Hostname from ApplicationDomain.Spec.Domain
        - BackendRef to Service on ApplicationDomain.Spec.Port
        - Set OwnerReference to ApplicationDomain CR

        Reference: See ingress.yaml section 4.2, 4.3, 4.4
      acceptance_criteria:
        - TLSRoute created with correct spec
        - Routes attached to correct Gateway listener
        - SNI routing works
        - TLS passthrough (no termination at Gateway)

  application_domain_reconciler_reference_grant:
    - status: "[ ]"
      task: "Implement ReferenceGrant creation in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add function to create ReferenceGrant in project namespace:
        - Allow HTTPRoute/TLSRoute to reference Service in same namespace
        - Potentially allow access to wildcard certificates

        Note: May not be strictly necessary for same-namespace references,
        but good practice for security model
      acceptance_criteria:
        - ReferenceGrant created if needed
        - Cross-namespace references work correctly

  application_domain_reconciler_certificate_ref:
    - status: "[ ]"
      task: "Implement certificate reference logic in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add logic to set ApplicationDomain.Status.CertificateRef:
        - For web app default domains (*.apps.{domain}):
          * Use shared tenant-wildcard-certificate from certificates namespace
        - For database default domains:
          * MySQL (*.mysql.{domain}): Create individual Certificate CR in project namespace
          * PostgreSQL (*.postgres.{domain}): Create individual Certificate CR in project namespace
          * Valkey (*.valkey.{domain}): Create individual Certificate CR in project namespace
          * Each database gets its own certificate for security isolation
        - For custom domains (both web and database):
          * Create individual Certificate CR in project namespace
          * Use exact domain match (not wildcard)

        Reference: See ingress.yaml section 5
      acceptance_criteria:
        - Status.CertificateRef populated correctly
        - Web apps use shared wildcard certificate
        - Each database has its own certificate in project namespace
        - Certificate exists and is ready
        - TLS works for the domain

  application_domain_reconciler_status_updates:
    - status: "[ ]"
      task: "Implement status updates in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Update ApplicationDomain status during reconciliation:
        - Phase: Pending -> Ready
        - CertificateReady: monitor certificate status
        - IngressReady: monitor HTTPRoute/TLSRoute status
        - Set appropriate Conditions
        - Update Message with human-readable info

        Reference: See ingress.yaml section 6.1
      acceptance_criteria:
        - Status accurately reflects resource state
        - Phase transitions correctly
        - Conditions provide useful debugging info

  application_domain_reconciler_main_flow:
    - status: "[ ]"
      task: "Implement main reconciliation flow in ApplicationDomainReconciler"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Enhance Reconcile() with complete flow:
        1. Fetch ApplicationDomain
        2. Handle deletion
        3. Add finalizer
        4. Fetch parent Application
        5. Determine application type
        6. Set certificate reference
        7. Create ReferenceGrant (if needed)
        8. Create HTTPRoute (web apps) OR TLSRoute (databases)
        9. Update status
        10. Requeue if resources not ready

        Reference: See ingress.yaml section 6.1
      acceptance_criteria:
        - Complete reconciliation flow implemented
        - Handles all application types
        - Error handling and retries
        - Status updates correctly

  rbac_permissions:
    - status: "[ ]"
      task: "Add RBAC permissions for Gateway API resources"
      timing: "Development"
      location: "internal/controller/applicationdomain_controller.go"
      details: |
        Add kubebuilder RBAC markers for:
        - gateway.networking.k8s.io/httproutes (create, get, list, watch, update, patch, delete)
        - gateway.networking.k8s.io/tlsroutes (create, get, list, watch, update, patch, delete)
        - gateway.networking.k8s.io/referencegrants (create, get, list, watch, update, patch, delete)
        - gateway.networking.k8s.io/gateways (get, list, watch)

        Also add RBAC for Kubernetes resources:
        - apps/deployments (create, get, list, watch, update, patch, delete)
        - core/services (create, get, list, watch, update, patch, delete)
      acceptance_criteria:
        - RBAC markers added
        - make manifests generates correct ClusterRole
        - Operator has necessary permissions

  owner_references:
    - status: "[ ]"
      task: "Set OwnerReferences for all created resources"
      timing: "Development"
      location: "internal/controller/deployment_controller.go and applicationdomain_controller.go"
      details: |
        Ensure all created resources have OwnerReferences:
        - Kubernetes Deployment -> owned by Deployment CR
        - Kubernetes Service -> owned by Deployment CR
        - HTTPRoute -> owned by ApplicationDomain CR
        - TLSRoute -> owned by ApplicationDomain CR
        - ReferenceGrant -> owned by ApplicationDomain CR

        This enables cascading deletion
      acceptance_criteria:
        - All resources have correct OwnerReferences
        - Deleting Deployment CR deletes K8s resources
        - Deleting ApplicationDomain CR deletes routes

  error_handling:
    - status: "[ ]"
      task: "Implement comprehensive error handling"
      timing: "Development"
      location: "All reconcilers"
      details: |
        Add error handling for:
        - Resource creation failures
        - Gateway not ready
        - Certificate not ready
        - Service not found
        - Invalid configurations

        Update status with error messages
        Implement exponential backoff for retries
      acceptance_criteria:
        - Errors logged clearly
        - Status shows failure reasons
        - Reconciler recovers from transient failures

  unit_tests:
    - status: "[ ]"
      task: "Write unit tests for new reconciler functions"
      timing: "Development"
      location: "internal/controller/*_test.go"
      details: |
        Write tests for:
        - createKubernetesDeployment()
        - createKubernetesService()
        - ensureApplicationDomain()
        - HTTPRoute creation
        - TLSRoute creation
        - Application type detection
        - Random slug generation
      acceptance_criteria:
        - Test coverage > 80%
        - All happy paths tested
        - Error cases tested
        - Edge cases handled

# ==============================================================================
# QUICK START GUIDE FOR BOOTSTRAP IMPLEMENTATION
# ==============================================================================
bootstrap_implementation_order:
  description: "Recommended order to implement bootstrap changes"

  step_1:
    - "Update constants in internal/bootstrap/provision.go"
    - "Change: ingressGatewayNS -> gatewayAPISystemNS"
    - "Change: gatewayName to 'kibaship-gateway'"
    - "Add: databaseWildcardCertName constant"

  step_2:
    - "Remove old HTTPRoute functions"
    - "Delete: ensureHTTPRedirectRoute()"
    - "Delete: ensureHTTPSRoute()"
    - "Delete: ensureDeploymentNotFoundRoute()"
    - "Delete: ensureDeploymentNotFoundWorkload()"
    - "Remove their calls from ProvisionIngressAndCertificates()"

  step_3:
    - "Update ensureWildcardCertificate() to use *.apps.{domain}"
    - "REMOVED ensureDatabaseWildcardCertificate() - databases get individual certificates"
    - "Each database will get its own certificate in its project namespace (handled by reconciler)"

  step_4:
    - "Add ensureGateway() function"
    - "Create Gateway with 5 listeners (HTTP, HTTPS, MySQL, Valkey, PostgreSQL)"
    - "Call from ProvisionIngressAndCertificates()"

  step_5:
    - "Add ensureGatewayReferenceGrant() function"
    - "Create ReferenceGrant for gateway-api-system to access certificates"
    - "Call from ProvisionIngressAndCertificates()"

  step_6:
    - "Test: Deploy operator and verify all bootstrap resources created"
    - "Verify: namespace gateway-api-system exists"
    - "Verify: Gateway kibaship-gateway exists with 5 listeners"
    - "Verify: Wildcard certificate for web apps (*.apps.{domain}) created"
    - "Verify: ReferenceGrant allows Gateway to access certificates"
    - "Note: Database certificates NOT created at bootstrap - created per-instance by reconciler"

# ==============================================================================
# END OF TASK LIST
# ==============================================================================
